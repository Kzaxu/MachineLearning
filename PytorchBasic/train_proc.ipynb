{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整训练套路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据集\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch \n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(\"./_data\", train=True, \n",
    "            transform=torchvision.transforms.ToTensor())\n",
    "test_data = torchvision.datasets.CIFAR10(\"./_data\", train=False, \n",
    "            transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# length 长度 \n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "print(f\"训练集数据的长度为：{train_data_size}\")\n",
    "print(f\"测试集数据的长度为：{test_data_size}\")\n",
    "\n",
    "# 利用 DataLoader 加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建神经网络\n",
    "class Foo(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)        \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证网络输入输出准确性\n",
    "foo = Foo()\n",
    "input_t = torch.ones((64, 3, 32, 32))\n",
    "output = foo(input_t)\n",
    "print(f\"输出的维度为：{output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 创建模型\n",
    "foo = Foo()\n",
    "# 定义损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.SGD(foo.parameters(), lr=1e-2)\n",
    "\n",
    "# 设置训练网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 10\n",
    "\n",
    "\n",
    "# 添加 tensorboard \n",
    "writer = SummaryWriter(\"./_log/train_proc\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(f\"-------------第{i}轮训练开始-------------\")\n",
    "\n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs, labels = data\n",
    "        outputs = foo(imgs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step += 1\n",
    "        # 记录训练信息\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(f\"训练次数：{total_train_step}，loss：{loss}\")\n",
    "            writer.add_scalar(\"train_loss\", loss, total_train_step)\n",
    "\n",
    "    # 测试步骤开始\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            imgs, labels = data\n",
    "            outputs = foo(imgs)\n",
    "            preds = outputs.argmax(1)\n",
    "            total_accuracy += (preds == labels).sum()\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_test_loss += loss\n",
    "\n",
    "    print(f\"整体测试集上的loss：{total_test_loss}\")\n",
    "    print(f\"整体测试集上的准确率：{total_accuracy/test_data_size}\")\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\", total_accuracy/test_data_size, total_test_step)\n",
    "    total_test_step += 1\n",
    "\n",
    "    torch.save(foo, f\"./_model/foo_{i}.pth\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用 GPU 进行训练\n",
    "\n",
    "方式：  \n",
    "对以下对象调用 .cuda() 方法\n",
    "1. 网络模型\n",
    "2. 数据（输入，标注）\n",
    "3. 损失函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = Foo()\n",
    "# 模型调用 cuda\n",
    "# 使用判断增加泛用性\n",
    "if torch.cuda.is_available():\n",
    "    foo = foo.cuda()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# 损失调用 cuda\n",
    "loss_fn = loss_fn.cuda()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(foo.parameters(), lr=1e-2)\n",
    "total_train_step = 0\n",
    "total_test_step = 0\n",
    "epoch = 10\n",
    "\n",
    "\n",
    "# 添加 tensorboard \n",
    "writer = SummaryWriter(\"./_log/train_proc\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(f\"-------------第{i}轮训练开始-------------\")\n",
    "\n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs, labels = data\n",
    "        # 数据调用 cuda \n",
    "        imgs, labels = imgs.cuda(), labels.cuda()\n",
    "        outputs = foo(imgs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step += 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(f\"训练次数：{total_train_step}，loss：{loss}\")\n",
    "            writer.add_scalar(\"train_loss\", loss, total_train_step)\n",
    "\n",
    "    # 测试步骤开始\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            imgs, labels = data\n",
    "            imgs, labels = imgs.cuda(), labels.cuda()\n",
    "            outputs = foo(imgs)\n",
    "            preds = outputs.argmax(1)\n",
    "            total_accuracy += (preds == labels).sum()\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_test_loss += loss\n",
    "\n",
    "    print(f\"整体测试集上的loss：{total_test_loss}\")\n",
    "    print(f\"整体测试集上的准确率：{total_accuracy/test_data_size}\")\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\", total_accuracy/test_data_size, total_test_step)\n",
    "    total_test_step += 1\n",
    "\n",
    "    torch.save(foo, f\"./_model/foo_{i}.pth\")\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二种调用 GPU 方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练设备\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "foo = Foo()\n",
    "foo = foo.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0146373c32dc03127ec6bba3fe790e42078c8d1cee5cdf638507b26396ff2a1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}