{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积层\n",
    "\n",
    "### torch.nn 中的卷积层与 torch.nn.functional 差别\n",
    "torch.nn.functional 中的方法常使用在 forward 内部。以卷积层举例，如果把 F.conv2d 中的参数 weights 先使用 nn.Parameters\n",
    "在 __init__ 方法中进行注册，然后在 forward 内部调用 F.conv2d，这个操作和直接使用 nn.conv2d 是等同的。  \n",
    "\n",
    "换句话说，torch.nn 中的 Layer 将参数直接封装好了，在 __init__ 中初始化中直接将参数进行注册，\n",
    "而 torch.nn.functional 则将参数开放了出来，完全可以用做一个固定的 tensor 不进行更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F.conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 5, 5])\n",
      "torch.Size([1, 1, 3, 3])\n",
      "tensor([[[[10, 12, 12],\n",
      "          [18, 16, 16],\n",
      "          [13,  9,  3]]]])\n",
      "tensor([[[[10, 12],\n",
      "          [13,  3]]]])\n",
      "tensor([[[[ 1,  3,  4, 10,  8],\n",
      "          [ 5, 10, 12, 12,  6],\n",
      "          [ 7, 18, 16, 16,  8],\n",
      "          [11, 13,  9,  3,  4],\n",
      "          [14, 13,  9,  7,  4]]]])\n"
     ]
    }
   ],
   "source": [
    "input_t = torch.tensor([\n",
    "    [1, 2, 0, 3, 1],\n",
    "    [0, 1, 2, 3, 1],\n",
    "    [1, 2, 1, 0, 0],\n",
    "    [5, 2, 3, 1, 1],\n",
    "    [2, 1, 0, 1, 1]\n",
    "])\n",
    "\n",
    "kernel = torch.tensor([\n",
    "    [1, 2, 1],\n",
    "    [0, 1, 0],\n",
    "    [2, 1, 0]\n",
    "])\n",
    "\n",
    "input_t = input_t.reshape((1, 1, 5, 5))\n",
    "kernel = kernel.reshape((1, 1, 3, 3))\n",
    "print(input_t.shape)\n",
    "print(kernel.shape)\n",
    "\n",
    "output = F.conv2d(input_t, kernel, stride=1)\n",
    "print(output)\n",
    "\n",
    "output2 = F.conv2d(input_t, kernel, stride=2)\n",
    "print(output2)\n",
    "\n",
    "output3 = F.conv2d(input_t, kernel, stride=1, padding=1)\n",
    "print(output3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 6, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\"./_data\", train=False, \n",
    "            transform=torchvision.transforms.ToTensor(), download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "class Foo(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x \n",
    "\n",
    "foo = Foo()\n",
    "\n",
    "imgs, labels = next(iter(dataloader)) \n",
    "output = foo(imgs)\n",
    "print(imgs.shape)\n",
    "print(output.shape)\n",
    "\n",
    "writor = SummaryWriter(\"./_log/conv\")\n",
    "writor.add_images(\"input\", imgs)\n",
    "\n",
    "# output 有6个channel，无法进行\n",
    "writor.add_images(\"output\", output.reshape((-1, 3, 30, 30)))\n",
    "writor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 池化层\n",
    "池化层默认kernel移动的方式与卷积层不同，池化层的kernel默认移动时要保证互不相交。\n",
    "stride=kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 5, 5])\n",
      "tensor([[[[2., 3.],\n",
      "          [5., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "input_t = torch.tensor([\n",
    "    [1, 2, 0, 3, 1],\n",
    "    [0, 1, 2, 3, 1],\n",
    "    [1, 2, 1, 0, 0],\n",
    "    [5, 2, 3, 1, 1],\n",
    "    [2, 1, 0, 1, 1]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "input_t = input_t.reshape((-1, 1, 5, 5))\n",
    "print(input_t.shape)\n",
    "\n",
    "class Foo(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.maxpool1 = nn.MaxPool2d(3, ceil_mode=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.maxpool1(x)\n",
    "        return output\n",
    "\n",
    "foo = Foo()\n",
    "print(foo(input_t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(\"./_data\", train=False, \n",
    "            transform=torchvision.transforms.ToTensor(), download=False)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "imgs, labels = next(iter(dataloader))\n",
    "writor = SummaryWriter(\"./_log/maxpool\")\n",
    "writor.add_images(\"input\", imgs)\n",
    "writor.add_images(\"output\", foo(imgs))\n",
    "writor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0146373c32dc03127ec6bba3fe790e42078c8d1cee5cdf638507b26396ff2a1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}